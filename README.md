# DP_FL
Differential Privacy in Federated Learning
Federated Learning (FL) has been integrated with parameter-efficient fine-tuning (PEFT) methods for Large Language Models (LLMs) to protect the privacy of distributed users at the edge. However, even with FL, privacy leakage remains a concern. To address this, we incorporate differential privacy into federated fine-tuning of LLMs. Through extensive experiments, we evaluate the performance of two PEFT methods—Low-Rank Adaptation (LoRA) and Adapters—and demonstrate that, in our specific problem setup, Adapters can outperform LoRA, despite LoRA being generally favored for its efficiency in standard settings.
More details in annotated-DP.LoRA.pdf
